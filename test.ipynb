{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pipeline of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.utils.data_loading_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path=\"data/MLinApp_course_data/tcga_mir_label.csv\"\n",
    "data_path=\"data/MLinApp_course_data/tcga_mir_rpm.csv\"\n",
    "\n",
    "miRna_labels, miRna_data, miRna_tissues = load_data(data_path, label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data: class balancing, normalization and split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miRna_data, miRna_labels , _, _, _, _ = class_balancing(miRna_labels, miRna_data, miRna_tissues)\n",
    "\n",
    "miRna_data = normalize_data(miRna_data)\n",
    "\n",
    "train_data, test_data, train_label, test_label = split_data(miRna_data, miRna_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are gonna use only the test data because we don't need to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intelligent Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.metadata_functions import *\n",
    "from src.utils.utils import *\n",
    "from src.utils.statistics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These superclasses are selected in the training phase of the representation procesess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superclasses = { '0' :\n",
    "    ['BRCA', 'KICH', 'KIRC', 'LUAD', 'LUSC', 'MESO', 'SARC', 'UCEC'], '1' :\n",
    "    ['BLCA', 'CESC', 'HNSC', 'KIRP', 'PAAD', 'READ', 'STAD'], '2' :\n",
    "    ['DLBC', 'LGG', 'PRAD', 'TGCT', 'THYM', 'UCS'], '3' :\n",
    "    ['ACC', 'CHOL', 'LIHC'], '4' :\n",
    "    ['ESCA', 'PCPG', 'SKCM', 'THCA', 'UVM']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata creation and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_superlabel = lab2super(test_label, superclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovo, ovr = load_ovo_ovr('_trained_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of test metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = meta_data_creation_test(ovo, ovr, test_data, test_superlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = load_model('src/models/metadata/', 'rf_trained_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rf.predict(meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_matrix(test_superlabel, prediction, superclasses.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some statistics\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_superlabel, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN and SCNN classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add all the test pipeline of the CNN and SCNN classification.\n",
    "from src.utils.dataloader import load_dataset\n",
    "from src.models.CNN import CNN\n",
    "from src.models.SCNN import SCNN\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'mps'\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "# device = get_device()\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superclasses = [\n",
    "    ['BRCA', 'KICH', 'KIRC', 'LUAD', 'LUSC', 'MESO', 'SARC', 'UCEC'],\n",
    "    ['BLCA', 'CESC', 'HNSC', 'KIRP', 'PAAD', 'READ', 'STAD'],\n",
    "    ['DLBC', 'LGG', 'PRAD', 'TGCT', 'THYM', 'UCS'],\n",
    "    ['ACC', 'CHOL', 'LIHC'],\n",
    "    ['ESCA', 'PCPG', 'SKCM', 'THCA', 'UVM']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params(typeof='cnn', num_class=0):\n",
    "    '''\n",
    "    Load the parameters of the model.\n",
    "\n",
    "    Args:\n",
    "        typeof (str): type of the model, cnn or scnn.\n",
    "        num_class (int): number of classes.\n",
    "\n",
    "    Returns:\n",
    "        params (dict): dictionary with the parameters of the model.\n",
    "    '''\n",
    "    assert typeof.startswith(('cnn', 'scnn')), 'Type of model not supported'\n",
    "    params_path = os.path.join('data', 'params', typeof, f'{typeof}_class{num_class}.json')\n",
    "\n",
    "    return json.loads(open(params_path).read())\n",
    "\n",
    "def set_model(model_name: str, num_class: int, params: dict):\n",
    "    '''\n",
    "    Set the model with its parameters, given the name of the model, the class number and the parameters.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): name of the model.\n",
    "        num_class (int): class index.\n",
    "        params (dict): dictionary with the parameters of the model.\n",
    "    \n",
    "    Returns:\n",
    "        model (nn.Module): model with the parameters set.\n",
    "    '''\n",
    "    filter_numbers = [params['nf1'], params['nf2'], params['nf3']]\n",
    "    convolution_windows = [params['cw1'], params['cw2'], params['cw3']]\n",
    "    max_pooling_windows = [params['pw1'], params['pw2'], params['pw3']]\n",
    "    dropout = [params['dropout_0'], params['dropout_1']]\n",
    "    final_nf = params['nf4']\n",
    "    \n",
    "    if model_name.startswith('cnn'):\n",
    "        model = CNN(num_class, filter_numbers, convolution_windows, max_pooling_windows, final_nf, dropout)\n",
    "    else:\n",
    "        model = SCNN(num_class, filter_numbers, convolution_windows, max_pooling_windows, final_nf, dropout)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def load_model(model_path: str, typeof: str, num_class: int, params: dict):\n",
    "    '''\n",
    "    Load the model given the path, the type and the class number.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): path of the model.\n",
    "        typeof (str): type of the model.\n",
    "        num_class (int): class index.\n",
    "\n",
    "    Returns:\n",
    "        model (nn.Module): model loaded.\n",
    "    '''\n",
    "    assert typeof.startswith(('cnn', 'scnn')), 'Type of model not supported'\n",
    "    filepath = os.path.join(model_path, f'{typeof}_class{num_class}.pth')\n",
    "    model = set_model(typeof, num_class, params)\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    return correct\n",
    "\n",
    "def experiment(model_name: str, params: dict, metalabel: int, labels_of_metaclass, epochs:int, mode: str = 'train'):\n",
    "    num_classes = len(labels_of_metaclass)\n",
    "\n",
    "    print(f'METACLASS LABELS: {labels_of_metaclass}')\n",
    "    train_dataloader, test_dataloader = load_dataset(name='cancer', batch_size=params['batch_size'],\n",
    "                                                     metalabel=metalabel, labels_of_metaclass=labels_of_metaclass)\n",
    "\n",
    "    if mode == 'train':\n",
    "        model = set_model(model_name, num_classes, params)\n",
    "    else:\n",
    "        model = load_model(os.path.join('data', 'models', model_name), model_name, metalabel, params)\n",
    "    epochs = epochs  # TODO: be careful\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=params['lr'])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "        if mode == 'train':\n",
    "            train(train_dataloader, model, loss_fn, optimizer)\n",
    "        accuracy = test(test_dataloader, model, loss_fn)\n",
    "        print(accuracy)\n",
    "    print(\"Done!\")\n",
    "    print(f\"Accuracy for superclass {metalabel}: {accuracy}\")\n",
    "\n",
    "    \n",
    "    # input('Premi un tasto per concludere l esperimento...')\n",
    "    save_filepath = os.path.join('data', 'models', model_name)\n",
    "    if not os.path.exists(save_filepath):\n",
    "        os.makedirs(save_filepath)\n",
    "\n",
    "    if mode == 'train':    \n",
    "        torch.save(model.state_dict(), os.path.join(save_filepath, f'{model_name}_class{metalabel}.pth'))\n",
    "\n",
    "    # Call the save_model function to save the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cnn'\n",
    "metalabel = 0\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for metalabel in range(5):\n",
    "    params = load_params(model_name, metalabel)\n",
    "    metaclass_labels = superclasses[metalabel]\n",
    "    experiment(\n",
    "        model_name=model_name,\n",
    "        params=params,\n",
    "        metalabel= metalabel,\n",
    "        labels_of_metaclass=metaclass_labels,\n",
    "        epochs=epochs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_params(model_name, metalabel)\n",
    "metaclass_labels = superclasses[metalabel]\n",
    "\n",
    "experiment(\n",
    "    model_name=model_name,\n",
    "    params=params,\n",
    "    metalabel= metalabel,\n",
    "    labels_of_metaclass=metaclass_labels,\n",
    "    epochs=epochs,\n",
    "    mode='test'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
